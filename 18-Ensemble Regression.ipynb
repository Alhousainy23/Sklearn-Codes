{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
      "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
      "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
      "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
      "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
      "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
      "\n",
      "   tax  ptratio   black  lstat  medv  \n",
      "0  296     15.3  396.90   4.98  24.0  \n",
      "1  242     17.8  396.90   9.14  21.6  \n",
      "2  242     17.8  392.83   4.03  34.7  \n",
      "3  222     18.7  394.63   2.94  33.4  \n",
      "4  222     18.7  396.90   5.33  36.2  \n",
      "******************************************************************************************\n",
      "(506, 14)\n",
      "******************************************************************************************\n",
      "(506,)\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "import pandas as pd     \n",
    "#----------------------------------------------------\n",
    "dataset = pd.read_csv('D:\\\\Programming\\\\Machine Learning Projects\\\\My Projects\\\\Data\\\\Boston.csv')\n",
    "print(dataset.head())\n",
    "print('***'*30)\n",
    "x_data = dataset.iloc[:,:-1]\n",
    "y_target = dataset.iloc[:,-1] \n",
    "print(x_data.shape)\n",
    "#print(x_data[:5])\n",
    "print('***'*30)\n",
    "print(y_target.shape)\n",
    "#print(y_target[:5])\n",
    "print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Train Score is :  0.7745065255996815\n",
      "Random Forest Regressor Test Score is :  0.7104782358952905\n",
      "Random Forest Regressor No. of features are :  14\n",
      "----------------------------------------------------\n",
      "Predicted Value for Random Forest Regressor is :  [14.49342743 14.49342743 21.5832208  25.41548609 18.18133117 34.84881404\n",
      " 21.22051127 21.5832208  24.96864907 24.69344033]\n",
      "Mean Absolute Error Value is :  3.77618642832205\n",
      "Mean Squared Error Value is :  28.476735975693273\n",
      "Median Squared Error Value is :  2.718048037469501\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_target, test_size=0.33, random_state=44, shuffle =True)\n",
    "#Splitted Data\n",
    "#print('X_train shape is ' , X_train.shape)\n",
    "#print('X_test shape is ' , X_test.shape)\n",
    "#print('y_train shape is ' , y_train.shape)\n",
    "#print('y_test shape is ' , y_test.shape)\n",
    "#----------------------------------------------------\n",
    "#Applying Random Forest Regressor Model \n",
    "'''\n",
    "sklearn.ensemble.RandomForestRegressor(n_estimators='warn', criterion=’mse’, max_depth=None,\n",
    "min_samples_split=2, min_samples_leaf=1,min_weight_fraction_leaf=0.0,\n",
    "max_features=’auto’, max_leaf_nodes=None,min_impurity_decrease=0.0,\n",
    "min_impurity_split=None, bootstrap=True,oob_score=False, n_jobs=None,\n",
    "random_state=None, verbose=0,warm_start=False)'''\n",
    "RandomForestRegressorModel = RandomForestRegressor(n_estimators=100,max_depth=2, random_state=33)\n",
    "RandomForestRegressorModel.fit(X_train, y_train)\n",
    "#Calculating Details\n",
    "print('Random Forest Regressor Train Score is : ' , RandomForestRegressorModel.score(X_train, y_train))\n",
    "print('Random Forest Regressor Test Score is : ' , RandomForestRegressorModel.score(X_test, y_test))\n",
    "print('Random Forest Regressor No. of features are : ' , RandomForestRegressorModel.n_features_in_)\n",
    "print('----------------------------------------------------')\n",
    "#Calculating Prediction\n",
    "y_pred = RandomForestRegressorModel.predict(X_test)\n",
    "print('Predicted Value for Random Forest Regressor is : ' , y_pred[:10])\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )\n",
    "print('===========================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18146984 0.81473937 0.00145312 0.00233767]\n",
      "[-8.32987858]\n",
      "[0.37, 0.08, 0.2, 0.38]        [-2.98]\n",
      "[0.31, 0.42, 0.29, 0.39]        [16.95]\n",
      "[0.03, 0.86, 0.76, 0.79]        [20.14]\n",
      "[0.89, 0.56, 0.25, 0.69]        [26.01]\n",
      "[0.79, 0.45, 0.52, 0.1]        [24.2]\n",
      "[0.19, 0.61, 0.88, 0.66]        [17.79]\n",
      "[0.43, 0.15, 0.95, 0.6]        [8.59]\n",
      "[0.98, 0.09, 0.59, 0.98]        [0.55]\n",
      "[0.53, 0.03, 0.22, 0.11]        [-2.31]\n",
      "[0.2, 0.86, 0.71, 0.47]        [20.88]\n",
      "[0.76, 0.37, 0.15, 0.97]        [18.06]\n",
      "[0.68, 0.48, 0.65, 0.43]        [20.03]\n",
      "[0.82, 0.51, 0.6, 0.54]        [25.16]\n",
      "[0.81, 0.46, 0.63, 0.13]        [24.61]\n",
      "[0.94, 0.43, 0.93, 0.74]        [25.16]\n",
      "[0.47, 0.77, 0.98, 0.35]        [21.82]\n",
      "[0.36, 0.48, 0.52, 0.85]        [16.95]\n",
      "[0.72, 0.05, 0.1, 0.43]        [-0.85]\n",
      "[0.53, 0.99, 0.93, 0.22]        [37.04]\n",
      "[0.05, 0.98, 0.85, 0.16]        [34.89]\n"
     ]
    }
   ],
   "source": [
    "#Another Example \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\n",
    "regr.fit(X, y)\n",
    "print(regr.feature_importances_)\n",
    "print(regr.predict([[0, 0, 0, 0]]))\n",
    "for i in range(20):\n",
    "    l = list(np.round(np.random.random(4),2))\n",
    "    print(l , '      ' ,np.round(regr.predict([ l ]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970408918644713\n",
      "[ 66.24995567  25.95441111  60.41079333  89.88228867  36.11314667\n",
      "  53.659175    48.33813333  95.68720833 116.09889667  45.70581644\n",
      " 119.15719167  38.11286333  63.66075     42.65134333  30.419444\n",
      " 152.97896333  41.36948333  36.60294156  54.77471667  21.51299333\n",
      "  28.78317067  26.864763    68.73369133  46.203902    69.467375\n",
      "  40.07776267  60.54850578  58.31631     49.65575267  60.81076667\n",
      "  25.20037333  56.11786667  21.59254     32.07118333  20.89688667\n",
      "  74.57150767  23.86974533  50.39307333  42.28373667  77.44335833\n",
      "  24.95928     54.71898333  29.99481667  28.717659    27.71306267\n",
      "  28.443056    36.28988467  51.96064867  45.74023333  58.43053533\n",
      "  53.51916667  73.36382667  63.37281467  20.919845    64.616442\n",
      "  78.18988867  84.471717    36.06878833  30.57495     48.41423\n",
      "  89.31354533  25.524201    89.19910733  54.0532      61.887796\n",
      "  49.69561667  38.85536311  36.84112667  58.90459533  27.92451567\n",
      "  25.80587733  22.72289333  22.81583267  69.987943    22.63068811\n",
      "  43.29520867  51.02657133  26.40788067  46.58377667  75.477642\n",
      "  86.07067467  73.347222    30.64051667  40.44176667  28.98955\n",
      "  28.32466667  24.32827667  33.21946667  49.48833367  27.8876\n",
      "  31.86937533  50.165475    41.36948333  28.80156633  63.080226\n",
      "  35.62067778  50.62560667  24.87921     31.293633    36.36858367\n",
      " 105.293541    76.12370667  27.70146067  50.22187333  56.37658133\n",
      "  35.29065     27.68948933  37.59040867  45.84372333  39.84844\n",
      "  39.26493333  48.30595667  33.8189      32.57011011  43.76745667\n",
      "  63.171864    24.249048    23.33683389  64.73888667 103.17321\n",
      "  25.37176     65.168622    22.70695     43.92439167 110.90857333\n",
      "  39.92675     25.99550067  32.25602733  69.789392    49.1827\n",
      "  24.91035133  23.74995056  43.29424333  88.08098033  50.143006\n",
      "  62.02546667  22.95257767  68.07839095  24.840652    77.77649333\n",
      "  34.71824867  34.158592    67.25750333 121.43518767  72.46463033\n",
      "  25.419238    83.449187    28.05540767  53.54613067  56.529778\n",
      "  29.60141667  63.69944667 148.228       44.34747     24.52673833\n",
      "  45.19294433  51.01747933  31.95643467  55.54201533  57.39212956\n",
      "  27.01494333  27.92384533  25.46511567  72.90141367  43.878071\n",
      "  59.641216    29.532868    22.17419889  28.378968    59.83136333\n",
      "  29.54695     25.69662767 113.99506     73.825912    41.93670667\n",
      "  43.81436     26.79456233  44.53694267  68.28685     58.744417\n",
      "  35.791172    48.377996    55.25764667  62.729078    20.43595278\n",
      "  25.594701    22.78674406  33.519       25.05845     40.03162667\n",
      "  23.34136333 177.14766667  34.06733133  66.73893533  18.51661111\n",
      "  36.93411667  62.276067    76.09307867  26.32757     38.06866333\n",
      "  36.02605     50.13989722  37.58654667  75.42022     67.098775\n",
      "  48.079642    79.77545156  75.96027267  52.3793      66.62408667\n",
      " 117.614494    80.58794933  58.04427533  70.02472    118.6491\n",
      "  42.39813867  20.73447933  91.16620667  41.60169933  77.86066267\n",
      "  47.98513933  26.156012    64.06243     31.85063333  38.70407667\n",
      "  30.49958333  46.03544267  26.34913867  85.88008367  45.690214\n",
      "  48.62513333  32.92856667  46.63080933  58.30327     76.335805\n",
      "  30.40999     35.39154267  24.42530167  25.79456833  53.26778333\n",
      "  60.17013667  61.93257667  78.43956033  35.97827267  33.02713333\n",
      "  37.92965667  42.85298667 171.08499333 163.0382      30.97133333\n",
      "  46.40888     71.61945333 144.54766667  27.36798533  44.06180833\n",
      "  63.13302     42.44216667  39.610055   145.36352     43.64508867\n",
      "  65.73530067  22.64586933  30.5314      46.48186667  49.33150533\n",
      "  50.50488333  44.24107067  36.18563333  55.98274967  22.68785933\n",
      "  30.25542489  29.318133    26.00199433  27.131453    31.76118967\n",
      "  48.679056    25.53895267  29.01642033  58.25347333  35.244646\n",
      "  26.12488767  86.24493333  46.77951733  42.62810333  31.89371667\n",
      "  56.89908333  33.74563333  25.97341633  35.39361667  47.01166667\n",
      "  80.80794067  49.93732933  41.52056678  36.612232    33.99337533\n",
      " 138.46506667  30.98033333  26.10322222  24.130753    34.107594\n",
      "  29.9592      22.65683067 127.54563333  51.81964867  47.5014\n",
      "  52.52247333  31.45801678  25.834014    40.16893067  31.50521967\n",
      "  72.23765033  68.990219    40.57506333  22.63541667  31.66438333\n",
      "  28.45320067  42.58050667  50.59699667  68.56362733  61.69779\n",
      "  32.60402133  52.95126667  86.30678667  24.22245267  39.78199044\n",
      "  54.5557      30.49453333  22.24561633  52.45105     22.56463056]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('D:\\\\AI\\\\10 القسم العاشر  مكتبة سايكيتليرن Sklearn Library\\\\Materials\\Data\\\\2.9 Ensemble Reg\\\\houses.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X)\n",
    "X= imp.transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# Fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 300, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "print(regressor.score(X_train, y_train))\n",
    "# Predicting a new result\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (348, 12)\n",
      "Training Features Shape: (261, 17)\n",
      "Training Labels Shape: (261,)\n",
      "Testing Features Shape: (87, 17)\n",
      "Testing Labels Shape: (87,)\n",
      "Mean Absolute Error: 3.87 degrees.\n",
      "Accuracy: 93.93 %.\n"
     ]
    }
   ],
   "source": [
    "#Another Example \n",
    "import pandas as pd\n",
    "features = pd.read_csv('D:\\\\AI\\\\10 القسم العاشر  مكتبة سايكيتليرن Sklearn Library\\\\Materials\\Data\\\\2.9 Ensemble Reg\\\\data.csv')\n",
    "features.head(5)\n",
    "print('The shape of our features is:', features.shape)\n",
    "features.describe()\n",
    "features = pd.get_dummies(features)\n",
    "features.iloc[:,5:].head(5)\n",
    "import numpy as np\n",
    "labels = np.array(features['actual'])\n",
    "features= features.drop('actual', axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = 100 * (errors / test_labels)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
      "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
      "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
      "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
      "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
      "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
      "\n",
      "   tax  ptratio   black  lstat  medv  \n",
      "0  296     15.3  396.90   4.98  24.0  \n",
      "1  242     17.8  396.90   9.14  21.6  \n",
      "2  242     17.8  392.83   4.03  34.7  \n",
      "3  222     18.7  394.63   2.94  33.4  \n",
      "4  222     18.7  396.90   5.33  36.2  \n",
      "******************************************************************************************\n",
      "(506, 14)\n",
      "******************************************************************************************\n",
      "(506,)\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Another Example \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "import pandas as pd     \n",
    "#----------------------------------------------------\n",
    "dataset = pd.read_csv('D:\\\\Programming\\\\Machine Learning Projects\\\\My Projects\\\\Data\\\\Boston.csv')\n",
    "print(dataset.head())\n",
    "print('***'*30)\n",
    "x_data = dataset.iloc[:,:-1]\n",
    "y_target = dataset.iloc[:,-1] \n",
    "print(x_data.shape)\n",
    "#print(x_data[:5])\n",
    "print('***'*30)\n",
    "print(y_target.shape)\n",
    "#print(y_target[:5])\n",
    "print('***'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBRModel Train Score is :  0.9964770573009347\n",
      "GBRModel Test Score is :  0.5985913613331206\n",
      "----------------------------------------------------\n",
      "Predicted Value for GBRModel is :  [16.58318573 20.40250205 23.70972976 33.00126997 10.60852936 36.05290399\n",
      " 21.14421673 25.24598836 24.43609058 29.17180356]\n",
      "Mean Absolute Error Value is :  4.238010008370221\n",
      "Mean Squared Error Value is :  39.481687523653925\n",
      "Median Squared Error Value is :  2.8124097778229533\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_target, test_size=0.33, random_state=44, shuffle =True)\n",
    "#Splitted Data\n",
    "#print('X_train shape is ' , X_train.shape)\n",
    "#print('X_test shape is ' , X_test.shape)\n",
    "#print('y_train shape is ' , y_train.shape)\n",
    "#print('y_test shape is ' , y_test.shape)\n",
    "#----------------------------------------------------\n",
    "#Applying Gradient Boosting Regressor Model \n",
    "'''\n",
    "sklearn.ensemble.GradientBoostingRegressor(loss='ls’, learning_rate=0.1,n_estimators=100, subsample=\n",
    "1.0, criterion='friedman_mse’,min_samples_split=2,min_samples_leaf=1,\n",
    "min_weight_fraction_leaf=0.0,max_depth=3,min_impurity_decrease=0.0,\n",
    "min_impurity_split=None,init=None, random_state=None,max_features=None, alpha=0.9,\n",
    "verbose=0, max_leaf_nodes=None,warm_start=False, presort='auto'\n",
    ", validation_fraction=0.1,n_iter_no_change=None, tol=0.0001)\n",
    "'''\n",
    "GBRModel = GradientBoostingRegressor(n_estimators=100,max_depth=2,learning_rate = 1.5 ,random_state=33)\n",
    "GBRModel.fit(X_train, y_train)\n",
    "#Calculating Details\n",
    "print('GBRModel Train Score is : ' , GBRModel.score(X_train, y_train))\n",
    "print('GBRModel Test Score is : ' , GBRModel.score(X_test, y_test))\n",
    "print('----------------------------------------------------')\n",
    "#Calculating Prediction\n",
    "y_pred = GBRModel.predict(X_test)\n",
    "print('Predicted Value for GBRModel is : ' , y_pred[:10])\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Absolute Error\n",
    "MAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Absolute Error Value is : ', MAEValue)\n",
    "#----------------------------------------------------\n",
    "#Calculating Mean Squared Error\n",
    "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\n",
    "print('Mean Squared Error Value is : ', MSEValue)\n",
    "#----------------------------------------------------\n",
    "#Calculating Median Squared Error\n",
    "MdSEValue = median_absolute_error(y_test, y_pred)\n",
    "print('Median Squared Error Value is : ', MdSEValue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282796978090049"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import  make_friedman1\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "x , y = make_friedman1(n_samples = 1000 , noise = 1)\n",
    "xtrain , xtest , ytrain , ytest = train_test_split(x , y , test_size = 0.3 )\n",
    "model = GradientBoostingRegressor(n_estimators = 100 , learning_rate = 1.5 , max_depth = 1)\n",
    "model.fit(xtrain , ytrain)\n",
    "model.predict(xtest)\n",
    "mean_squared_error(ytest , model.predict(xtest))\n",
    "model.score(xtest , ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (348, 12)\n",
      "Training Features Shape: (261, 17)\n",
      "Training Labels Shape: (261,)\n",
      "Testing Features Shape: (87, 17)\n",
      "Testing Labels Shape: (87,)\n",
      "Mean Absolute Error: 5.25 degrees.\n",
      "Accuracy: 91.49 %.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "features = pd.read_csv('D:\\\\AI\\\\10 القسم العاشر  مكتبة سايكيتليرن Sklearn Library\\\\Materials\\Data\\\\2.9 Ensemble Reg\\\\data.csv')\n",
    "features.head(5)\n",
    "print('The shape of our features is:', features.shape)\n",
    "features.describe()\n",
    "features = pd.get_dummies(features)\n",
    "features.iloc[:,5:].head(5)\n",
    "import numpy as np\n",
    "labels = np.array(features['actual'])\n",
    "features= features.drop('actual', axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators = 100 , learning_rate = 1.5 , max_depth = 1)\n",
    "model.fit(train_features, train_labels)\n",
    "predictions = model.predict(test_features)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = 100 * (errors / test_labels)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for  100  estimators is  4.690823405999596\n",
      "Score for  100  estimators is  0.8182268114708702\n",
      "======================================\n",
      "MSE for  200  estimators is  3.6507593938844147\n",
      "Score for  200  estimators is  0.8585301303966631\n",
      "======================================\n",
      "MSE for  300  estimators is  3.6880600127581755\n",
      "Score for  300  estimators is  0.8570847013450981\n",
      "======================================\n",
      "MSE for  400  estimators is  3.662239174310905\n",
      "Score for  400  estimators is  0.8580852796506153\n",
      "======================================\n",
      "MSE for  500  estimators is  3.6982947927028125\n",
      "Score for  500  estimators is  0.8566880953713896\n",
      "======================================\n",
      "MSE for  600  estimators is  3.760464893004607\n",
      "Score for  600  estimators is  0.8542789538657471\n",
      "======================================\n",
      "MSE for  700  estimators is  3.8230947032488363\n",
      "Score for  700  estimators is  0.8518519982292363\n",
      "======================================\n",
      "MSE for  800  estimators is  3.868215316643048\n",
      "Score for  800  estimators is  0.8501035380858495\n",
      "======================================\n",
      "MSE for  900  estimators is  3.9372267964504264\n",
      "Score for  900  estimators is  0.84742928760913\n",
      "======================================\n",
      "MSE for  1000  estimators is  3.9963841675668004\n",
      "Score for  1000  estimators is  0.8451368917881595\n",
      "======================================\n",
      "MSE for  1100  estimators is  4.059937708319657\n",
      "Score for  1100  estimators is  0.8426741408497662\n",
      "======================================\n",
      "MSE for  1200  estimators is  4.123705463544193\n",
      "Score for  1200  estimators is  0.8402030889279045\n",
      "======================================\n",
      "MSE for  1300  estimators is  4.159046937775887\n",
      "Score for  1300  estimators is  0.8388335783106005\n",
      "======================================\n",
      "MSE for  1400  estimators is  4.2081725306413125\n",
      "Score for  1400  estimators is  0.8369299219840564\n",
      "======================================\n",
      "MSE for  1500  estimators is  4.293716732238053\n",
      "Score for  1500  estimators is  0.8336150152100068\n",
      "======================================\n",
      "MSE for  1600  estimators is  4.339313873272473\n",
      "Score for  1600  estimators is  0.8318480892364053\n",
      "======================================\n",
      "MSE for  1700  estimators is  4.371729569211711\n",
      "Score for  1700  estimators is  0.8305919548865746\n",
      "======================================\n",
      "MSE for  1800  estimators is  4.40443276499027\n",
      "Score for  1800  estimators is  0.8293246796861997\n",
      "======================================\n",
      "MSE for  1900  estimators is  4.442981977724219\n",
      "Score for  1900  estimators is  0.8278308666159879\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "#End Example \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\n",
    "X_train = X[:200]\n",
    "X_test  = X[200:]\n",
    "y_train = y[:200]\n",
    "y_test  = y[200:]\n",
    "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='huber').fit(X_train, y_train)\n",
    "mean_squared_error(y_test, est.predict(X_test))\n",
    "est.score(X_train,y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "###########################################################################\n",
    "for g in range(100,2000 , 100):\n",
    "    est = GradientBoostingRegressor(n_estimators=g, learning_rate=0.1,max_depth=1, random_state=0, loss='huber').fit(X_train, y_train)\n",
    "    score = est.score(X_test, y_test)\n",
    "    y_pred = est.predict(X_test)\n",
    "    print('MSE for ' , g , ' estimators is ' , mean_squared_error(y_test, y_pred))\n",
    "    print('Score for ',g,' estimators is ',score)\n",
    "    print('======================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14a256fa5d2abe453c482b40db541c720d938562dda362430172368847a78a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
