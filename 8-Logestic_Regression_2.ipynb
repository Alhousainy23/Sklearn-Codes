{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score Of Data Is ==>  0.9666666666666667\n",
      "Number Of Iterations Is ==>  [85]\n",
      "Number Of Classes Is ==>  [0 1 2]\n",
      "******************************************************************************************\n",
      "The Score Of Data Is ==>  0.96\n",
      "Number Of Iterations Is ==>  [7 7 6]\n",
      "Number Of Classes Is ==>  [0 1 2]\n",
      "******************************************************************************************\n",
      "The Score Of Data Is ==>  0.9866666666666667\n",
      "Number Of Iterations Is ==>  [100]\n",
      "Number Of Classes Is ==>  [0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "X,y=load_iris(return_X_y=True)\n",
    "clf1=LogisticRegression(random_state=10,solver='lbfgs',max_iter=1000,C=0.5,tol=0.01)\n",
    "clf2=LogisticRegression(random_state=10,solver='liblinear')\n",
    "clf3=LogisticRegression(random_state=10,solver='saga')\n",
    "clf1.fit(X,y)\n",
    "clf1.predict(X[:10,:])\n",
    "clf1.predict_proba(X[:10,:])\n",
    "score=clf1.score(X,y)\n",
    "print('The Score Of Data Is ==> ',score)\n",
    "print('Number Of Iterations Is ==> ',clf1.n_iter_)\n",
    "print('Number Of Classes Is ==> ',clf1.classes_)\n",
    "#=================================================================================================================================\n",
    "#CLF2 \n",
    "#=============================================================\n",
    "print('***'*30)\n",
    "clf2.fit(X,y)\n",
    "clf2.predict(X[:10,:])\n",
    "clf2.predict_proba(X[:10,:])\n",
    "score1=clf2.score(X,y)\n",
    "print('The Score Of Data Is ==> ',score1)\n",
    "print('Number Of Iterations Is ==> ',clf2.n_iter_)\n",
    "print('Number Of Classes Is ==> ',clf2.classes_)\n",
    "#=================================================================================================================================\n",
    "#CLF3 \n",
    "#=============================================================\n",
    "print('***'*30)\n",
    "clf3.fit(X,y)\n",
    "clf3.predict(X[:10,:])\n",
    "clf3.predict_proba(X[:10,:])\n",
    "score2=clf3.score(X,y)\n",
    "print('The Score Of Data Is ==> ',score2)\n",
    "print('Number Of Iterations Is ==> ',clf3.n_iter_)\n",
    "print('Number Of Classes Is ==> ',clf3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Show 5 Rows From Data Is \n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n",
      "3   0     2       1  \n",
      "4   0     2       1  \n",
      "******************************************************************************************\n",
      "\t\t The First 5 Rows From X Data \n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "\n",
      "   ca  thal  \n",
      "0   0     1  \n",
      "1   0     2  \n",
      "2   0     2  \n",
      "3   0     2  \n",
      "4   0     2  \n",
      "************************************************************\n",
      "\t\t The First 5 Rows From Y Target \n",
      " 0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: target, dtype: int64\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Another Example For Hearts Dataset \n",
    "import pandas as pd     \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "#==========================================================\n",
    "#First Read Data \n",
    "#==========================================================\n",
    "dataset = pd.read_csv('D:\\\\AI\\\\10 القسم العاشر  مكتبة سايكيتليرن Sklearn Library\\\\Materials\\\\Data\\\\2.2 Logistic Regression\\\\heart.csv')\n",
    "print('\\t\\t Show 5 Rows From Data Is \\n',dataset.head(5))\n",
    "print('***'*30)\n",
    "#Splitting Data To ==> X  & Y \n",
    "x_data =dataset.iloc[:,:-1]\n",
    "y_target =dataset.iloc[:,-1]\n",
    "print('\\t\\t The First 5 Rows From X Data \\n',x_data.head(5))\n",
    "print('***'*20)\n",
    "print('\\t\\t The First 5 Rows From Y Target \\n',y_target.head(5))\n",
    "print('***'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t The X Training Data Is \n",
      "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "173   58    1   2       132   224    0        0      173      0      3.2   \n",
      "261   52    1   0       112   230    0        1      160      0      0.0   \n",
      "37    54    1   2       150   232    0        0      165      0      1.6   \n",
      "\n",
      "     slope  ca  thal  \n",
      "173      2   2     3  \n",
      "261      2   1     2  \n",
      "37       2   0     3  \n",
      "********************************************************************************\n",
      "\t\t The X Test Data Is \n",
      "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "225   70    1   0       145   174    0        1      125      1      2.6   \n",
      "152   64    1   3       170   227    0        0      155      0      0.6   \n",
      "228   59    1   3       170   288    0        0      159      0      0.2   \n",
      "\n",
      "     slope  ca  thal  \n",
      "225      0   0     3  \n",
      "152      1   0     3  \n",
      "228      1   0     3  \n",
      "********************************************************************************\n",
      "\t\t The Y Training Data Is \n",
      " 173    0\n",
      "261    0\n",
      "37     1\n",
      "Name: target, dtype: int64\n",
      "********************************************************************************\n",
      "\t\t The Y Test Data Is \n",
      " 225    0\n",
      "152    1\n",
      "228    0\n",
      "Name: target, dtype: int64\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Splitting My Data into Training Data & Test Data \n",
    "X_train,X_test,y_train,y_test = train_test_split(x_data,y_target,test_size=0.25,random_state=0)\n",
    "print('\\t\\t The X Training Data Is \\n',X_train[:3])\n",
    "print('****'*20)\n",
    "print('\\t\\t The X Test Data Is \\n',X_test[:3])\n",
    "print('****'*20)\n",
    "print('\\t\\t The Y Training Data Is \\n',y_train[:3])\n",
    "print('****'*20)\n",
    "print('\\t\\t The Y Test Data Is \\n',y_test[:3])\n",
    "print('****'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t The X Training Data Is \n",
      " [[ 0.35256528  0.70243936  0.9870291   0.02020565 -0.43596979 -0.42695628\n",
      "  -0.9825655   1.01189274 -0.72352604  1.72483977  0.96222601  1.22723311\n",
      "   1.12135917]\n",
      " [-0.31068598  0.70243936 -0.91982712 -1.1409796  -0.32539421 -0.42695628\n",
      "   0.89174012  0.45363971 -0.72352604 -0.92348745  0.96222601  0.25993479\n",
      "  -0.45968761]\n",
      " [-0.08960223  0.70243936  0.9870291   1.06527237 -0.28853568 -0.42695628\n",
      "  -0.9825655   0.66835241 -0.72352604  0.40067616  0.96222601 -0.70736353\n",
      "   1.12135917]\n",
      " [ 0.46310716  0.70243936  1.94045721  2.69093172  0.4117763  -0.42695628\n",
      "  -0.9825655  -0.19049841 -0.72352604  2.55244203 -2.27370441 -0.70736353\n",
      "   1.12135917]\n",
      " [ 1.34744218  0.70243936 -0.91982712 -0.6765055  -0.34382347 -0.42695628\n",
      "  -0.9825655  -0.87757907  1.38212026  1.22827842 -0.6557392   1.22723311\n",
      "   1.12135917]]\n",
      "********************************************************************************\n",
      "\t\t The X Test Data Is \n",
      " [[ 1.67906782  0.70243936 -0.91982712  0.77497606 -1.35743293 -0.42695628\n",
      "   0.89174012 -1.04934923  1.38212026  1.22827842 -2.27370441 -0.70736353\n",
      "   1.12135917]\n",
      " [ 1.01581655  0.70243936  1.94045721  2.22645762 -0.380682   -0.42695628\n",
      "  -0.9825655   0.238927   -0.72352604 -0.4269261  -0.6557392  -0.70736353\n",
      "   1.12135917]\n",
      " [ 0.46310716  0.70243936  1.94045721  2.22645762  0.74350304 -0.42695628\n",
      "  -0.9825655   0.41069717 -0.72352604 -0.757967   -0.6557392  -0.70736353\n",
      "   1.12135917]\n",
      " [ 0.57364904  0.70243936 -0.91982712 -0.38620919  0.19062515 -0.42695628\n",
      "  -0.9825655  -0.36226857  1.38212026  1.39379887 -0.6557392   0.25993479\n",
      "   1.12135917]\n",
      " [ 0.79473279  0.70243936  0.9870291  -0.09591288 -0.30696495 -0.42695628\n",
      "   0.89174012 -0.14755587 -0.72352604  0.56619661 -0.6557392   2.19453143\n",
      "   1.12135917]]\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Apply Standar Scaler Becuase All Values Is That Between -1 to 1 \n",
    "sc =StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "print('\\t\\t The X Training Data Is \\n',X_train[:5])\n",
    "print('****'*20)\n",
    "print('\\t\\t The X Test Data Is \\n',X_test[:5])\n",
    "print('****'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t The Values Of Y Predictions \n",
      " [0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1]\n",
      "******************************************************************************************************************************************************\n",
      "\t\t The Predictions Values Is \n",
      " [[0.96421264 0.03578736]\n",
      " [0.18275371 0.81724629]\n",
      " [0.18628997 0.81371003]\n",
      " [0.98171588 0.01828412]\n",
      " [0.88161474 0.11838526]\n",
      " [0.62175492 0.37824508]\n",
      " [0.93007085 0.06992915]\n",
      " [0.8983798  0.1016202 ]\n",
      " [0.99539398 0.00460602]\n",
      " [0.9973351  0.0026649 ]]\n",
      "******************************************************************************************************************************************************\n",
      "\t\t The Predictions Probabalities Values \n",
      " [0.96421264 0.18275371 0.18628997 0.98171588 0.88161474 0.62175492\n",
      " 0.93007085 0.8983798  0.99539398 0.9973351 ]\n",
      "******************************************************************************************************************************************************\n",
      "\t\t The Predictions Probabalities Values one Column \n",
      " [0.03578736 0.81724629 0.81371003 0.01828412 0.11838526 0.37824508\n",
      " 0.06992915 0.1016202  0.00460602 0.0026649 ]\n",
      "******************************************************************************************************************************************************\n",
      "\tConfusion Matrix \n",
      " [[24  9]\n",
      " [ 4 39]]\n",
      "******************************************************************************************************************************************************\n",
      "0.17105263157894737\n",
      "0.17105263157894737\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Applying Logestic Regression Model \n",
    "clss=LogisticRegression(random_state=0)\n",
    "clss.fit(X_train,y_train)\n",
    "#Predicting The Test Set Results \n",
    "y_pred1=clss.predict(X_test)\n",
    "print('\\t\\t The Values Of Y Predictions \\n',y_pred1)\n",
    "print('***'*50)\n",
    "#probability of all values\n",
    "pr = clss.predict_proba(X_test)[0:10,:]\n",
    "print('\\t\\t The Predictions Values Is \\n',pr)\n",
    "print('***'*50)\n",
    "#probability of zeros\n",
    "pr = clss.predict_proba(X_test)[0:10,0]\n",
    "print('\\t\\t The Predictions Probabalities Values \\n',pr)\n",
    "print('***'*50)\n",
    "#probability of ones\n",
    "pr = clss.predict_proba(X_test)[0:10,1]\n",
    "print('\\t\\t The Predictions Probabalities Values one Column \\n',pr)\n",
    "print('***'*50)\n",
    "#  Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print('\\tConfusion Matrix \\n',cm) \n",
    "print('***'*50)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, y_pred1))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred1))\n",
    "from sklearn.metrics import median_absolute_error\n",
    "print(median_absolute_error(y_test, y_pred1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tThe Matrix Of X Data Is \n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "************************************************************************************************************************\n",
      "\t\t The Matrix Of Y Data Is \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "#Loaded Data \n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('\\t\\tThe Matrix Of X Data Is \\n',X[:10])\n",
    "print('**'*60)\n",
    "print('\\t\\t The Matrix Of Y Data Is \\n',y[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t The Train Data Is \n",
      " [ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "******************************************************************************************\n",
      "\t\t The Test Data Is \n",
      " [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "******************************************************************************************\n",
      "\t\t The Result Is \n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2]\n",
      "******************************************************************************************\n",
      "The Accuracy Score Is ==>   0.9666666666666667\n",
      "=======================================================================\n",
      "\t\t The Train Data Is \n",
      " [  0   1   2   3   4   5   6   7   8   9  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "******************************************************************************************\n",
      "\t\t The Test Data Is \n",
      " [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "******************************************************************************************\n",
      "\t\t The Result Is \n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "******************************************************************************************\n",
      "The Accuracy Score Is ==>   1.0\n",
      "=======================================================================\n",
      "\t\t The Train Data Is \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "******************************************************************************************\n",
      "\t\t The Test Data Is \n",
      " [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "******************************************************************************************\n",
      "\t\t The Result Is \n",
      " [0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 2 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "******************************************************************************************\n",
      "The Accuracy Score Is ==>   0.9333333333333333\n",
      "=======================================================================\n",
      "\t\t The Train Data Is \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 140 141 142 143 144 145 146 147 148 149]\n",
      "******************************************************************************************\n",
      "\t\t The Test Data Is \n",
      " [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "******************************************************************************************\n",
      "\t\t The Result Is \n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "******************************************************************************************\n",
      "The Accuracy Score Is ==>   0.9666666666666667\n",
      "=======================================================================\n",
      "\t\t The Train Data Is \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139]\n",
      "******************************************************************************************\n",
      "\t\t The Test Data Is \n",
      " [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "******************************************************************************************\n",
      "\t\t The Result Is \n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "******************************************************************************************\n",
      "The Accuracy Score Is ==>   1.0\n",
      "=======================================================================\n",
      "The Total Accuracy Is ==>  0.9733333333333334\n",
      "\t\t The Confusion Matrix Is \n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  1 49]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alhou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Applying StratifiedKFold\n",
    "#K = 5 \n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "#Creating Predicted Matrix Conatin Same Shape Of Y Matrix \n",
    "predict=np.zeros(y.shape[0])\n",
    "#Splitting Into Train & Test Data \n",
    "for train,test in skf.split(X,y):\n",
    "    x_train=X[train]\n",
    "    x_test=X[test]\n",
    "    y_train=y[train]\n",
    "    y_test=y[test]\n",
    "    LogReg_Model =LogisticRegression()\n",
    "    LogReg_Model.fit(x_train,y_train)\n",
    "    result=LogReg_Model.predict(x_test)\n",
    "    predict[test] = result  \n",
    "    print('\\t\\t The Train Data Is \\n',train)\n",
    "    print('***'*30)\n",
    "    print('\\t\\t The Test Data Is \\n',test)\n",
    "    print('***'*30)\n",
    "    print('\\t\\t The Result Is \\n',result)\n",
    "    print('***'*30)\n",
    "    print('The Accuracy Score Is ==>  ',accuracy_score(y_test,result))\n",
    "    print('=======================================================================')\n",
    "#=========================================================================================\n",
    "#To Know Total Accuracy \n",
    "print('The Total Accuracy Is ==> ',accuracy_score(y,predict))\n",
    "cm = confusion_matrix(y,predict)\n",
    "print('\\t\\t The Confusion Matrix Is \\n',cm)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14a256fa5d2abe453c482b40db541c720d938562dda362430172368847a78a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
